{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports and paths\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Paths\n",
    "working_directory=\"/Users/katherineridley/APPFIRE_image\"\n",
    "Lifs = os.path.join(working_directory, \"Lifs\")\n",
    "OMETIFFs = os.path.join(working_directory, \"OMETIFFs\")\n",
    "MaxPTIFFs = os.path.join(working_directory, \"MaxProjections\")\n",
    "\n",
    "\n",
    "#download bftools onto your machine, point to bfconvert here:\n",
    "bfconvert_path = \"/Users/katherineridley/Downloads/bftools/bfconvert\" \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert Lifs to Tiffs\n",
    "# Works with TWO channel images, splits them into separate stacks, saves as c0 and c1\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "if not os.path.exists(OMETIFFs):\n",
    "    os.makedirs(OMETIFFs)\n",
    "\n",
    "# Iterate through all .lif files in the input directory\n",
    "for filename in os.listdir(Lifs):\n",
    "    if filename.endswith(\".lif\"):\n",
    "        input_file = os.path.join(Lifs, filename)\n",
    "        \n",
    "\n",
    "        # Loop through each series and channel\n",
    "        \n",
    "        for channel in [0, 1]:\n",
    "                output_file = os.path.join(OMETIFFs, \"%n_c{}.ome.tiff\".format(channel))\n",
    "                command = f\"{bfconvert_path} -noflat -channel {channel} {input_file} {output_file}\"\n",
    "                subprocess.run(command, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Max Projections, create merged file for Max Projections for TWO CHANNELS ONLY\n",
    "\n",
    "if not os.path.exists(MaxPTIFFs):\n",
    "    os.makedirs(MaxPTIFFs)\n",
    "\n",
    "processed_files = {}  # To keep track of processed files for merging\n",
    "\n",
    "# Loop through all .ome.tiff files in the input directory\n",
    "for filename in os.listdir(OMETIFFs):\n",
    "    if filename.endswith(\".ome.tiff\"):\n",
    "        # Splitting filename to get base name and channel\n",
    "        parts = filename.split('_')\n",
    "        channel = parts[-1] \n",
    "        c = channel.split('.')[0]\n",
    "        #print(c, 'here is channel') # Assuming channel is the second last element\n",
    "        base_name = '_'.join(parts[:-1])\n",
    "        \n",
    "        image_path = os.path.join(OMETIFFs, filename)\n",
    "        output_path = os.path.join(MaxPTIFFs, f\"{base_name}_{c}_maxp.ome.tiff\")\n",
    "\n",
    "        process_image(image_path, output_path)\n",
    "\n",
    "        # Store the output paths for merging\n",
    "        if base_name not in processed_files:\n",
    "            processed_files[base_name] = {}\n",
    "        processed_files[base_name][c] = output_path\n",
    "            \n",
    "#print(processed_files)\n",
    "# Merge channels for each base image\n",
    "for base_name, channels in processed_files.items():\n",
    "    #print('both together at merge', base_name, channels)\n",
    "    if 'c0' in channels and 'c1' in channels:\n",
    "        \n",
    "        merge_channels(channels['c0'], channels['c1'], \n",
    "                       os.path.join(MaxPTIFFs, f\"{base_name}_maxp_merge.ome.tiff\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install aicsimageio scikit-image napari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.measure import label, regionprops\n",
    "import numpy as np\n",
    "import h5py\n",
    "import skimage.io as io\n",
    "from skimage.filters import threshold_otsu\n",
    "from scipy.ndimage import binary_fill_holes\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from skimage.transform import resize\n",
    "from matplotlib.colors import ListedColormap\n",
    "from skimage import io, exposure, data\n",
    "from skimage.filters import gaussian\n",
    "from skimage.filters import threshold_local\n",
    "from skimage.filters import try_all_threshold\n",
    "from skimage.filters import threshold_yen, sobel, threshold_isodata, threshold_multiotsu\n",
    "import napari\n",
    "import pandas as pd\n",
    "from skimage.segmentation import find_boundaries\n",
    "from napari.utils import nbscreenshot\n",
    "import imageio\n",
    "\n",
    "metadata = pd.read_csv('/Users/katherineridley/APPFIRE_image/TIFFs/metadata.csv')\n",
    "allocproperties=[]\n",
    "allmproperties=[]\n",
    "ocproperties = []\n",
    "mproperties=[]\n",
    "\n",
    "folder_path = '/Users/katherineridley/APPFIRE_image/TIFFs/ProcessedImages/A_4_M04_OC_P+_CA1_011123_1.tif/mask_window_stacks'\n",
    "\n",
    "input = '/Users/katherineridley/APPFIRE_image/TIFFs/ProcessedImages/'\n",
    "\n",
    "for path in os.listdir(input):\n",
    "    if path.endswith('.tif'):\n",
    "        imageinput = os.path.join(input, path, 'mask_window_stacks/')\n",
    "\n",
    "        print(path)\n",
    "\n",
    "    # Separate the images according to their protein stain (OC and Methoxy-0-4)\n",
    "        oc_stacks = []\n",
    "        methoxy_stacks = []\n",
    "\n",
    "        # Sort and stack the images\n",
    "\n",
    "\n",
    "        for filename in sorted(os.listdir(imageinput)):\n",
    "            if filename.endswith(\".tif\") or filename.endswith(\".tiff\"):\n",
    "                full_path = os.path.join(imageinput, filename)\n",
    "                # Load the image\n",
    "                image = io.imread(full_path)\n",
    "                #print(image)\n",
    "                # Append the image to the corresponding stack list\n",
    "                if \"OC\" in filename:\n",
    "                    oc_stacks.append(image)\n",
    "                elif \"Methoxy-0-4\" in filename:\n",
    "                    methoxy_stacks.append(image)\n",
    "\n",
    "        # Convert lists to 3D numpy arrays (stack them along the first axis)\n",
    "        oc_stack_array = np.stack(oc_stacks, axis=0)\n",
    "        methoxy_stack_array = np.stack(methoxy_stacks, axis=0)\n",
    "\n",
    "        '''with napari.gui_qt():\n",
    "            viewer = napari.Viewer()\n",
    "            \n",
    "            # Add the labeled OC stack to Napari. Each label will be visualized with a different color.\n",
    "            viewer.add_labels(oc_stack_array, name='OC Labeled', opacity=0.6)\n",
    "            \n",
    "            # Add the labeled methoxy stack to Napari in the same way.\n",
    "            viewer.add_labels(methoxy_stack_array, name='Methoxy Labeled', opacity=0.6)\n",
    "\n",
    "            napari.run()'''\n",
    "\n",
    "        # The arrays `oc_stack_array` and `methoxy_stack_array` now contain your stacked images for each protein\n",
    "\n",
    "        # From here, you can directly apply your morphological analysis\n",
    "        # For a simple example, we can calculate volumes of each labeled region\n",
    "        '''def analyze_morphology(stack):\n",
    "            \n",
    "            properties_list = []\n",
    "            for z_slice in stack:\n",
    "                # Ensure that z_slice is a NumPy array using np.asarray, in case it is not already\n",
    "                z_slice_array = np.asarray(z_slice)\n",
    "                #print('1', z_slice_array)\n",
    "                labeled_image = label(z_slice_array)\n",
    "                #print('2', labeled_image)\n",
    "                for region in regionprops(z_slice_array):\n",
    "                    properties = {\n",
    "                        'label': region.label,\n",
    "                        'volume': region.area,  # The area for each 2D region\n",
    "                        # ... other properties\n",
    "                    }\n",
    "                    properties_list.append(properties)\n",
    "            return properties_list\n",
    "\n",
    "        oc_properties = analyze_morphology(oc_stack_array)\n",
    "        methoxy_properties = analyze_morphology(methoxy_stack_array)\n",
    "\n",
    "        # Do something with the `oc_properties` and `methoxy_properties`, like saving to a DataFrame\n",
    "        import pandas as pd\n",
    "        oc_df = pd.DataFrame(oc_properties)\n",
    "        methoxy_df = pd.DataFrame(methoxy_properties)\n",
    "\n",
    "        # Save to CSV if needed\n",
    "        oc_df.to_csv('oc_morphology.csv', index=False)\n",
    "        methoxy_df.to_csv('methoxy_morphology.csv', index=False)\n",
    "\n",
    "        def analyze_morphology(labeled_stack):\n",
    "            properties = regionprops(labeled_stack)\n",
    "            for prop in properties:\n",
    "                volume = prop.area # In 2D, this will be the area\n",
    "                length = prop.major_axis_length\n",
    "                width = prop.minor_axis_length\n",
    "                # For 3D, consider the 3D properties such as prop.volume if you used a 3D labeling function\n",
    "                # Do something with these measurements, like saving to a DataFrame\n",
    "\n",
    "\n",
    "        '''\n",
    "\n",
    "        from skimage.measure import label, regionprops\n",
    "        from skimage.morphology import cube, closing\n",
    "        def analyze_morphology_3d(stack, name):\n",
    "            # Label the 3D stack\n",
    "            \n",
    "            # Define the structuring element for connectivity (e.g., face connectivity)\n",
    "            selem = cube(3)\n",
    "            \n",
    "            # Apply the closing operation to the 3D stack using the cube structuring element\n",
    "            closed_stack = closing(stack, selem)\n",
    "            \n",
    "            # Label the closed 3D stack\n",
    "            labeled_stack = label(closed_stack)\n",
    "\n",
    "            threedpath = os.path.join(input, path, 'closed_3D_objects/')\n",
    "            os.makedirs(threedpath, exist_ok=True)\n",
    "            io.imsave(threedpath+'/closed_3D_{}_{}.tif'.format(path[:3], name), labeled_stack.astype(np.uint16),check_contrast=False)\n",
    "    \n",
    "\n",
    "            properties=[]\n",
    "            \n",
    "            # Measure region properties in 3D\n",
    "            # Create an empty list to store our dictionaries of properties\n",
    "            for region in regionprops(labeled_stack):  \n",
    "                \n",
    "                volume = region.area\n",
    "                \n",
    "\n",
    "\n",
    "                \n",
    "                \n",
    "                # Pass the intensity image if needed\n",
    "                # Each region will have its 3D properties such as volume\n",
    "                props = {\n",
    "                    'image':path,\n",
    "                    'label': region.label,\n",
    "                    'volume': region.area,  # Here, 'area' is actually the 3D volume because we're using the 3D labeled stack\n",
    "                    'centroid': region.centroid,\n",
    "                    \n",
    "                    \n",
    "                    'extent': region.extent,\n",
    "\n",
    "                    'axis_major': region.axis_major_length,\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    'bbox': region.bbox\n",
    "\n",
    "                }\n",
    "\n",
    "                \n",
    "\n",
    "                properties.append(props)\n",
    "                \n",
    "            \n",
    "            return properties\n",
    "        \n",
    "        \n",
    "        # Now we call the function for our stacks:\n",
    "        oc_properties_3d = analyze_morphology_3d(oc_stack_array, 'OC')\n",
    "        methoxy_properties_3d = analyze_morphology_3d(methoxy_stack_array, \"Methoxy\")\n",
    "\n",
    "        allocproperties.append(oc_properties_3d)\n",
    "\n",
    "        allmproperties.append(methoxy_properties_3d)\n",
    "\n",
    "    # You can then use these properties as needed, possibly converting them to a DataFrame again:\n",
    "import pandas as pd\n",
    "oc_df_3d = pd.DataFrame(allocproperties)\n",
    "methoxy_df_3d = pd.DataFrame(allmproperties)\n",
    "\n",
    "# Save to CSV\n",
    "oc_df_3d.to_csv('oc_morphology_3d.csv', index=False)\n",
    "methoxy_df_3d.to_csv('methoxy_morphology_3d.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import skimage.io as io\n",
    "from skimage.filters import threshold_otsu\n",
    "from scipy.ndimage import label, binary_fill_holes\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from skimage.transform import resize\n",
    "from matplotlib.colors import ListedColormap\n",
    "from skimage import io, exposure, data\n",
    "from skimage.filters import gaussian\n",
    "from skimage.filters import threshold_local\n",
    "from skimage.filters import try_all_threshold\n",
    "from skimage.filters import threshold_yen, sobel, threshold_isodata, threshold_multiotsu\n",
    "import napari\n",
    "import pandas as pd\n",
    "from skimage.segmentation import find_boundaries\n",
    "from napari.utils import nbscreenshot\n",
    "import imageio\n",
    "metadata_dict = {}\n",
    "\n",
    "input_dir = \"/Users/katherineridley/APPFIRE_image/TIFFs/\"\n",
    "output_dir = \"/Users/katherineridley/APPFIRE_image/TIFFs/ProcessedImages/\"\n",
    "os.makedirs(output_dir, exist_ok=True)  # Create directory if it doesn't exist\n",
    "\n",
    "plaques = [image for image in os.listdir(input_dir) if ('P+' in image) & (image.endswith('.tif'))]\n",
    "\n",
    "\n",
    "# Initialize a dictionary to store masks for each channel\n",
    "fl_channels = [0,1]\n",
    "channel_masks = {}\n",
    "\n",
    "for image in plaques:\n",
    "\n",
    "    \n",
    "    # Initialize an entry for each image\n",
    "    '''channel_masks[image] = {channel: [] for channel in fl_channels}\n",
    "    channel_masks[image]['masks'] = []\n",
    "    channel_masks[image]['raw']=[]\n",
    "    channel_masks[image]['background_corrected']=[]\n",
    "    channel_masks[image]['central_masks']=[]\n",
    "    channel_masks[image]['binary_masks']=[]'''\n",
    "\n",
    "    print(image)\n",
    "\n",
    "    \n",
    "    # Construct the control image filename by replacing 'P+' with 'P-'\n",
    "    control_image = image.replace('P+', 'P-')\n",
    "\n",
    "    control_image_path = os.path.join(input_dir, control_image)\n",
    "\n",
    "    if not os.path.exists(control_image_path):\n",
    "        continue\n",
    "\n",
    "\n",
    "\n",
    "    # Read the experimental image stack\n",
    "    image_stack = io.imread(os.path.join(input_dir, image))\n",
    "\n",
    "    # Read the corresponding negative control image stack\n",
    "    control_stack = io.imread(os.path.join(input_dir, control_image))\n",
    "\n",
    "    # Ensure the dimensions match between the image and control stacks\n",
    "    if image_stack.shape != control_stack.shape:\n",
    "        print(f\"Mismatch in image and control stack dimensions for {image}. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    outputfolder = os.path.join(output_dir, image)\n",
    "    os.makedirs(outputfolder, exist_ok=True) \n",
    "    print('output', outputfolder)\n",
    "\n",
    "    rawfolder = os.path.join(outputfolder,'raw_image_stacks')\n",
    "    os.makedirs(rawfolder, exist_ok=True) \n",
    "\n",
    "    bgcorrectedfolder = os.path.join(outputfolder,'background_corrected_stacks')\n",
    "    os.makedirs(bgcorrectedfolder, exist_ok=True) \n",
    "\n",
    "    scaledfolder = os.path.join(outputfolder,'min_max_scaled_stacks')\n",
    "    os.makedirs(scaledfolder, exist_ok=True) \n",
    "\n",
    "    negfolder = os.path.join(outputfolder,'negative_control_stacks')\n",
    "    os.makedirs(negfolder, exist_ok=True) \n",
    "\n",
    "    fullmaskfolder = os.path.join(outputfolder,'full_mask_stacks')\n",
    "    os.makedirs(fullmaskfolder, exist_ok=True) \n",
    "\n",
    "    maskwindowfolder = os.path.join(outputfolder,'mask_window_stacks')\n",
    "    os.makedirs(maskwindowfolder, exist_ok=True) \n",
    "\n",
    "    imagewindowfolder = os.path.join(outputfolder,'image_window_stacks')\n",
    "    os.makedirs(imagewindowfolder, exist_ok=True) \n",
    "\n",
    "    binaryfolder = os.path.join(outputfolder,'binary_mask_stacks')\n",
    "    os.makedirs(binaryfolder, exist_ok=True) \n",
    "\n",
    "    threshsurface = os.path.join(outputfolder,'surface_boundaries')\n",
    "    os.makedirs(threshsurface, exist_ok=True) \n",
    "\n",
    "\n",
    "\n",
    "    # Define fluorescent channels\n",
    "\n",
    "\n",
    "    # Initialize a dictionary to store thresholds\n",
    "\n",
    "    for channel in fl_channels:\n",
    "        if channel == 0:\n",
    "            protein = 'Methoxy-0-4'\n",
    "\n",
    "        else:\n",
    "            protein = 'OC'\n",
    "\n",
    "        binary_masks = []\n",
    "        # Process each z-plane\n",
    "        for z_plane in range(image_stack.shape[0]):\n",
    "            # Calculate the central region\n",
    "            height, width = image_stack[z_plane, channel].shape\n",
    "            center_y, center_x = height // 2, width // 2\n",
    "            delta_y, delta_x = height // 4, width // 4  # 50% of the height and width\n",
    "            y_min, y_max = center_y - delta_y, center_y + delta_y\n",
    "            x_min, x_max = center_x - delta_x, center_x + delta_x\n",
    "\n",
    "            center_fraction = 0.4  # For example, use 40% of the height and width instead of 50%\n",
    "            delta_y, delta_x = int(height * center_fraction / 2), int(width * center_fraction / 2)\n",
    "            y_min, y_max = center_y - delta_y, center_y + delta_y\n",
    "            x_min, x_max = center_x - delta_x, center_x + delta_x\n",
    "\n",
    "            # Crop the smaller central region\n",
    "            central_region = image_stack[z_plane, channel][y_min:y_max, x_min:x_max]\n",
    "\n",
    "            central_control = control_stack[z_plane, channel][y_min:y_max, x_min:x_max]\n",
    "\n",
    "            backgroundthreshold = threshold_otsu(central_control)\n",
    "            originalthreshold = threshold_otsu(central_region)\n",
    "            #print('whole image:', np.mean(image_stack), 'central z plane:', np.mean(central_region), 'whole control:', np.mean(control_stack), 'control z plane:', np.mean(central_control))\n",
    "\n",
    "            background_corrected_image = (central_region.astype(np.float32) - (central_control.astype(np.float32)))\n",
    "            \n",
    "            # Set any negative values to zero\n",
    "            background_corrected_image[background_corrected_image < 0] = 0\n",
    "\n",
    "            hard_cutoff= 5\n",
    "            image_cutoff = image_stack > hard_cutoff\n",
    "            v_min, v_max = np.percentile(background_corrected_image, (0.05, 99.99))\n",
    "            # Apply threshold to the central region\n",
    "            image_minmax_scaled = exposure.rescale_intensity(background_corrected_image, in_range=(v_min, v_max), out_range=(0,50))\n",
    "            \n",
    "            #print('mean:', np.mean(image_minmax_scaled))\n",
    "            #print('max:',np.max(image_minmax_scaled))\n",
    "            #sigma=1\n",
    "            #blurred_image = gaussian(image_minmax_scaled, sigma=sigma, mode='nearest')\n",
    "            \n",
    "            #better_contrast = exposure.rescale_intensity(image_minmax_scaled[z_plane, channel], in_range=(v_min, v_max))\n",
    "            threshold_value = (threshold_otsu(image_minmax_scaled))\n",
    "\n",
    "            #threshold_value = threshold_local(central_region, block_size=3, offset=-0.1)\n",
    "\n",
    "            #apply thrshold from entire stack>>\n",
    "            '''image_minmax_scaled = exposure.rescale_intensity(image_stack)\n",
    "            sigma=0.1\n",
    "            #blurred_image = gaussian(image_stack, sigma=sigma, mode='nearest')\n",
    "            v_min, v_max = np.percentile(image_stack, (0.2, 99.8))\n",
    "\n",
    "            \n",
    "\n",
    "            better_contrast = exposure.rescale_intensity(image_minmax_scaled)\n",
    "            threshold_value = threshold_otsu(image_stack[:, channel])\n",
    "            intensity_cutoff = np.percentile(image_stack, 20) \n",
    "            if channel == 0:\n",
    "                offset = 0.3\n",
    "            else:\n",
    "                offset = 1\n",
    "            threshold_value = threshold_value * offset'''\n",
    "            \n",
    "            #binary_mask = central_region > threshold_value\n",
    "\n",
    "            #>>new code<<\n",
    "            #block_size = 35  # This is a parameter you may need to tune\n",
    "            #local_thresh = threshold_local(central_region, block_size, offset=50)\n",
    "            #binary_mask = central_region > local_thresh\n",
    "\n",
    "            binary_mask = central_region > threshold_value\n",
    "\n",
    "            #print(threshold_value)\n",
    "\n",
    "\n",
    "            \n",
    "            # Process the binary mask\n",
    "            filled_mask = binary_fill_holes(binary_mask)\n",
    "            cleaned_mask, _ = label(filled_mask)\n",
    "            size = np.bincount(cleaned_mask.flatten())\n",
    "\n",
    "            #print(threshold_value)\n",
    "            \n",
    "            binary_cleaned_mask = (cleaned_mask > 0).astype(int)\n",
    "            #print('sum', np.sum(binary_cleaned_mask), 'size:', binary_cleaned_mask.size)\n",
    "\n",
    "            print((np.sum(binary_cleaned_mask) / binary_cleaned_mask.size) * 100)\n",
    "            # Check the condition for empty mask\n",
    "            if ((threshold_value < 4.5) & (np.sum(binary_cleaned_mask) > 0.3 * binary_cleaned_mask.size)) | ((np.sum(binary_cleaned_mask) > 0.65 * binary_cleaned_mask.size)):\n",
    "                \n",
    "                #unique_values = np.unique(cleaned_mask)\n",
    "                #print(unique_values)\n",
    "                #if threshold_value < 4.5 and np.sum(cleaned_mask) > 0.9 * cleaned_mask.size:\n",
    "                cleaned_mask = np.zeros_like(cleaned_mask)\n",
    "            \n",
    "\n",
    "            # Check if there are non-zero elements in 'size' after the first element\n",
    "            if len(size) > 1:\n",
    "                largest_component = np.argmax(size[1:]) + 1\n",
    "                cleaned_mask = cleaned_mask == largest_component\n",
    "            else:\n",
    "                # If no connected components, use an empty mask\n",
    "                cleaned_mask = np.zeros_like(cleaned_mask)\n",
    "\n",
    "\n",
    "\n",
    "            # Create an empty mask for the whole image\n",
    "            full_cleaned_mask = np.zeros_like(image_stack[z_plane, channel])\n",
    "            # Place the processed central region back into the full mask\n",
    "            full_cleaned_mask[y_min:y_max, x_min:x_max] = cleaned_mask\n",
    "\n",
    "            #print(full_cleaned_mask)\n",
    "\n",
    "            # Instead of binary_masks.append, use:\n",
    "            '''channel_masks[image][channel].append(full_cleaned_mask)\n",
    "            channel_masks[image]['masks'].append(full_cleaned_mask)\n",
    "            \n",
    "            channel_masks[image]['raw'].append(image_stack)\n",
    "            channel_masks[image][channel].append(image_stack)\n",
    "            channel_masks[image]['background_corrected'].append(background_corrected_image)\n",
    "            channel_masks[image][channel].append(background_corrected_image)\n",
    "            channel_masks[image]['central_masks'].append(cleaned_mask)\n",
    "            channel_masks[image][channel].append(cleaned_mask)\n",
    "            channel_masks[image]['binary_masks'].append(binary_cleaned_mask)\n",
    "            channel_masks[image][channel].append(binary_cleaned_mask)\n",
    "\n",
    "            #save channel_masks\n",
    "\n",
    "            masks = {'z':z_plane,\n",
    "                     'channel':channel,\n",
    "                'raw':image_stack[z_plane, channel],\n",
    "                'controlraw':control_stack[z_plane, channel],\n",
    "                'backgroundcorrected':image_minmax_scaled,\n",
    "                'thresholdmask':full_cleaned_mask,\n",
    "                'binarymask':binary_cleaned_mask,\n",
    "                'thresholdwindow':cleaned_mask,\n",
    "                'rawwindow':central_region}\n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "            channel_masks[image] = masks\n",
    "\n",
    "            io.imsave(rawfolder+'/raw_{}_z{}_{}.tif'.format(image[:3], z_plane, protein), image_stack[z_plane, channel], check_contrast=False)\n",
    "            io.imsave(negfolder+'/control_{}_z{}_{}.tif'.format(image[:3], z_plane, protein), control_stack[z_plane, channel],check_contrast=False)\n",
    "            io.imsave(bgcorrectedfolder+'/bgcorr_{}_z{}_{}.tif'.format(image[:3], z_plane, protein), background_corrected_image,check_contrast=False)\n",
    "            io.imsave(scaledfolder+'/scaled_{}_z{}_{}.tif'.format(image[:3], z_plane, protein), image_minmax_scaled,check_contrast=False)\n",
    "            \n",
    "            io.imsave(maskwindowfolder+'/mask_{}_z{}_{}.tif'.format(image[:3], z_plane, protein), cleaned_mask,check_contrast=False)\n",
    "            io.imsave(imagewindowfolder+'/window_{}_z{}_{}.tif'.format(image[:3], z_plane, protein), central_region,check_contrast=False)\n",
    "            io.imsave(binaryfolder+'/binary_{}_z{}_{}.npy'.format(image[:3], z_plane, protein), binary_cleaned_mask,check_contrast=False)'''\n",
    "\n",
    "            stacked_boundaries = find_boundaries(cleaned_mask)\n",
    "\n",
    "            io.imsave(threshsurface+'/surface_{}_z{}_{}.npy'.format(image[:3], z_plane, protein), stacked_boundaries,check_contrast=False)\n",
    "        \n",
    "\n",
    "            #io.imsave(fullmaskfolder+'/mask_{}_z{}_{}.tiff'.format(image[:3], z_plane, protein), full_cleaned_mask, check_contrast=False)\n",
    "\n",
    "            '''parts = image.split('_')\n",
    "            metadata = {\n",
    "                'channel': channel,\n",
    "                'slide': parts[0],\n",
    "                'section': parts[1],\n",
    "                'region': parts[4],\n",
    "                'plaque': parts[5],\n",
    "                'date': parts[6],\n",
    "                'number': parts[7].split('.')[0]  # Assuming the file extension follows\n",
    "            }\n",
    "\n",
    "            # Add additional data\n",
    "            metadata['binarymasksize'] =np.sum(binary_cleaned_mask)\n",
    "            metadata['zplane'] = z_plane\n",
    "            metadata['znumber'] = image_stack.shape[0]\n",
    "            metadata['otsuthreshold'] = threshold_value\n",
    "            metadata['mean'] = np.mean(image_minmax_scaled)\n",
    "            \n",
    "\n",
    "            # Add the metadata to the dictionary with the image name as key\n",
    "            metadata_dict[image] = metadata\n",
    "\n",
    "            # After processing all images, add them to the viewer\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            #brightness_increase = 1000  # Adjust this value as needed\n",
    "\n",
    "            # Increase brightness\n",
    "            #brightened_image = image_stack + brightness_increase\n",
    "\n",
    "            image_minmax_scaled = exposure.rescale_intensity(background_corrected_image)\n",
    "            better_contrast = exposure.rescale_intensity(image_minmax_scaled)\n",
    "            v_min, v_max = np.percentile(image_stack, (0.2, 99.8))\n",
    "\n",
    "            \n",
    "            print('making plots')\n",
    "            better_contrast = exposure.rescale_intensity(image_stack, in_range=(v_min, v_max))\n",
    "\n",
    "            central_contrast = exposure.rescale_intensity(central_region, in_range=(v_min, v_max))\n",
    "            #fig, ax = try_all_threshold(z_plane, figsize=(10, 8), verbose=False)\n",
    "            #plt.show()\n",
    "\n",
    "            # Visualize the results\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            plt.suptitle(f'Protein {protein}, Z-Plane: {z_plane}')\n",
    "\n",
    "            # Display the original image for the current z-plane\n",
    "            plt.subplot(1, 2, 1)\n",
    "            plt.imshow(better_contrast[z_plane, channel], cmap='gray')\n",
    "            plt.title('Original Image')\n",
    "\n",
    "            # Display the segmented volume for the current z-plane\n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.imshow(full_cleaned_mask, cmap='gray')\n",
    "            plt.title('Segmented Volume')\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(outputfolder+f\"/{image}_{z_plane}_c{channel}_thresh_otsu.png\")\n",
    "            plt.close()\n",
    "\n",
    "            boundaries = find_boundaries(cleaned_mask)\n",
    "\n",
    "            # Visualize in Matplotlib\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            plt.imshow(cleaned_mask, cmap='gray')  # Show the original mask\n",
    "            plt.imshow(boundaries, cmap='Purples', alpha=0.5)  # Overlay boundaries\n",
    "            plt.title(f'Channel {channel} - z {z_plane} with Boundaries')\n",
    "            plt.savefig(outputfolder+f\"/{image}_{z_plane}_c{channel}_boundaries.png\")\n",
    "            plt.close()\n",
    "\n",
    "\n",
    "\n",
    "#maskdf = pd.DataFrame.from_dict(channel_masks, orient='index')\n",
    "#masks.to_csv(os.path.join(input_dir, 'masks.csv'))\n",
    "df=pd.DataFrame.from_dict(metadata_dict, orient='index')\n",
    "df.to_csv(os.path.join(input_dir, 'metadata.csv'))\n",
    "\n",
    "\n",
    "viewer = napari.Viewer()\n",
    "\n",
    "for image, channel_info in channel_masks.items():\n",
    "    # 'channel_info' is the nested dictionary for each image\n",
    "    for channel, masks in channel_info.items():\n",
    "        if channel == 'masks':\n",
    "            # This is the list of all masks, handle accordingly\n",
    "            # ... process 'mask_list' which contains all masks for this image ...\n",
    "            \n",
    "            stacked_masks = np.stack(masks, axis=0)\n",
    "            # Stack boundaries similarly\n",
    "            stacked_boundaries = np.stack([find_boundaries(mask) for mask in masks], axis=0)\n",
    "\n",
    "            # Add original mask\n",
    "            viewer.add_image(stacked_masks, name=f'Channel {channel} Masks', contrast_limits=(0, 1))\n",
    "\n",
    "            # Add boundaries as another layer\n",
    "            viewer.add_labels(stacked_boundaries, name=f'Channel {channel} Boundaries')\n",
    "\n",
    "            frames = []\n",
    "\n",
    "# Iterate through the z-stacks (slices) of the binary mask\n",
    "            for i in range(stacked_masks.shape[0]):  # Assuming the first dimension is the z-axis\n",
    "                frame = stacked_masks[i, :, :]  # Get the i-th slice of the mask\n",
    "                print('making gif')\n",
    "                # You might want to convert the binary mask to a suitable format for GIF\n",
    "                # For example, multiplying by 255 for a typical black-and-white representation\n",
    "                frame_image = (frame * 255).astype(np.uint8)\n",
    "                \n",
    "                # Append the frame to the list\n",
    "                frames.append(frame_image)\n",
    "\n",
    "            # Save the frames as a GIF\n",
    "            \n",
    "            imageio.mimsave(outputfolder+'c{channel}_gif.gif', frames, format='GIF', fps=10)  # Adjust fps as needed\n",
    "\n",
    "            print(\"GIF created at:\", output_path)\n",
    "\n",
    "            #napari.run()\n",
    "\n",
    "    \n",
    " \n",
    "\n",
    "            video_path = os.path.join(outputfolder, '3dvideo.mp4')\n",
    "\n",
    "            # Record a video\n",
    "            with napari.gui_qt():\n",
    "                # Set the desired duration and frames per second for the video\n",
    "                total_duration_sec = 5\n",
    "                fps = 30\n",
    "                ('Creating video')\n",
    "                total_frames = total_duration_sec * fps\n",
    "                for frame in range(total_frames):\n",
    "                    # Here you can modify the viewer, e.g., rotate or zoom\n",
    "                    # Example: Rotate the view\n",
    "                    viewer.dims.ndisplay = 3\n",
    "                    viewer.dims.point = [frame, frame, frame]  # Change this as needed\n",
    "                    # Capture the frame\n",
    "                    nbscreenshot(viewer, canvas_only=False).save(f'{frame}.png')\n",
    "\n",
    "                # Use imageio to compile the saved frames into a video\n",
    "                import imageio\n",
    "                with imageio.get_writer(video_path, fps=fps) as writer:\n",
    "                    for frame in range(total_frames):\n",
    "                        writer.append_data(imageio.imread(f'{frame}.png'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for channel in fl_channels:\n",
    "    binary_masks = []\n",
    "# Process each z-plane\n",
    "    for z_plane in range(image_stack.shape[0]):\n",
    "    # Create binary masks for each channel\n",
    "    \n",
    "    \n",
    "        threshold_value = thresholds[channel][z_plane]\n",
    "        binary_mask = image_stack[z_plane, channel] > threshold_value\n",
    "        binary_masks.append(binary_mask)\n",
    "\n",
    "        # Stack the binary masks to form a binary stack\n",
    "        binary_stack = np.stack(binary_masks)\n",
    "\n",
    "        # Fill holes in the binary mask\n",
    "        filled_stack = binary_fill_holes(binary_stack)\n",
    "\n",
    "        # Remove small structures or noise\n",
    "        cleaned_stack, _ = label(filled_stack)\n",
    "\n",
    "        # Select only the largest connected component (if needed)\n",
    "        size = np.bincount(cleaned_stack.flatten())\n",
    "        cleaned_stack = cleaned_stack == np.argmax(size[1:]) + 1\n",
    "\n",
    "        # Visualize the results\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.suptitle(f'Methoxy-0-4, Z-Plane: {z_plane}')\n",
    "\n",
    "        # Display the original image for the current z-plane\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(image_stack[z_plane, channel], cmap='gray')\n",
    "        plt.title('Original Image')\n",
    "\n",
    "        # Display the segmented volume for the current z-plane\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(cleaned_stack[z_plane], cmap='gray')\n",
    "        plt.title('Segmented Volume')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "image_stack = io.imread('/Users/katherineridley/APPFIRE_image/TIFFs/F_3_M04_OC_L1_P+_231123_1.tif')\n",
    "thresholds = {}\n",
    "# Assume your fluorescent channel is at index 1\n",
    "fl_channels = [0,1]\n",
    "#image_stack.shape[1]\n",
    "# Loop over each z-stack\n",
    "print(list(range(image_stack.shape[0])))\n",
    "for channel in fl_channels:\n",
    "    for z_plane in list(range(image_stack.shape[0])):\n",
    "        \n",
    "        # Initialize an empty list to store the threshold values\n",
    "        \n",
    "\n",
    "        # Apply Otsu's method to determine the threshold for each channel\n",
    "        \n",
    "        threshold = threshold_otsu(image_stack[z_plane, channel])\n",
    "        # Store the threshold in the nested dictionary\n",
    "        thresholds[channel][z_plane] = threshold\n",
    "\n",
    "\n",
    "    # Create a binary mask for each channel using the respective threshold\n",
    "    binary_stack = np.stack([image_stack[z_plane, channel] > threshold for channel, threshold in zip(fl_channels, thresholds)])\n",
    "\n",
    "    # Fill holes in the binary mask\n",
    "    filled_stack = binary_fill_holes(binary_stack)\n",
    "\n",
    "    # Remove small structures or noise\n",
    "    cleaned_stack, _ = label(filled_stack)\n",
    "\n",
    "    # Select only the largest connected component (if needed)\n",
    "    size = np.bincount(cleaned_stack.flatten())\n",
    "    cleaned_stack = cleaned_stack == np.argmax(size[1:]) + 1\n",
    "\n",
    "\n",
    "#z_plane = 15\n",
    "print(thresholds)\n",
    "# Display the original image\n",
    "for z_plane in list(range(image_stack.shape[0])):\n",
    "    plt.figure(figsize=(10, 5))  # Adjust the figure size as needed\n",
    "    plt.suptitle(f'Methoxy-0-4, Z-Plane: {z_plane}')\n",
    "\n",
    "    # Display the original image for the current z-plane\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(image_stack[z_plane, fl_channels[0]], cmap='gray')\n",
    "    plt.title('Original Image')\n",
    "\n",
    "    # Display the segmented volume for the current z-plane\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(cleaned_stack[z_plane], cmap='gray')\n",
    "    plt.title('Segmented Volume')\n",
    "\n",
    "    # Adjust the layout and show the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "# Apply Otsu's method to determine the threshold\n",
    "threshold1 = threshold_otsu(image_stack[:, fl_channel[0]])\n",
    "print(threshold1)\n",
    "\n",
    "# Applying the threshold to create a binary mask\n",
    "binary_stack1 = image_stack[:, fl_channel[0]] > (threshold1)\n",
    "\n",
    "# Fill holes in the binary mask\n",
    "filled_stack1 = binary_fill_holes(binary_stack1)\n",
    "\n",
    "# Remove small structures or noise\n",
    "cleaned_stack1, _ = label(filled_stack1)\n",
    "\n",
    "# Select only the largest connected component (if needed)\n",
    "size = np.bincount(cleaned_stack1.flatten())\n",
    "cleaned_stack1 = cleaned_stack1 == np.argmax(size[1:]) + 1\n",
    "\n",
    "# Apply Otsu's method to determine the threshold\n",
    "threshold2 = threshold_otsu(image_stack[:, fl_channel[1]])\n",
    "\n",
    "\n",
    "# Applying the threshold to create a binary mask\n",
    "binary_stack2 = image_stack[:, fl_channel[1]] > (threshold2)\n",
    "\n",
    "# Fill holes in the binary mask\n",
    "filled_stack2 = binary_fill_holes(binary_stack2)\n",
    "\n",
    "# Remove small structures or noise\n",
    "cleaned_stack2, _ = label(filled_stack2)\n",
    "\n",
    "# Select only the largest connected component (if needed)\n",
    "size = np.bincount(cleaned_stack2.flatten())\n",
    "cleaned_stack2 = cleaned_stack2 == np.argmax(size[1:]) + 1\n",
    "\n",
    "#z_plane = 15\n",
    "\n",
    "for z_plane in range(image_stack.shape[0]):\n",
    "\n",
    "# Display the original image\n",
    "    plt.figure()\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(image_stack[z_plane, fl_channel[1]], cmap='gray')\n",
    "    plt.title('Original Image')\n",
    "    plt.suptitle('OC')\n",
    "    # Display the segmented volume\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(cleaned_stack2[z_plane], cmap='gray')\n",
    "    plt.title('Segmented Volume')\n",
    "\n",
    "    # Adjust the layout and show the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from skimage.transform import resize\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "output_dir = \"/Users/katherineridley/APPFIRE_image/TIFFs/F_3_M04_OC_L1_P+_231123_1\"\n",
    "os.makedirs(output_dir, exist_ok=True)  # Create directory if it doesn't exist\n",
    "\n",
    "# Channel colors for visualization\n",
    "colors_rgb = [(0, 1, 0), (1, 0, 1)]\n",
    "\n",
    "# Create a custom colormap\n",
    "cmap = ListedColormap(colors_rgb)\n",
    "# Create a merged segmented volume\n",
    "merged_stack = np.logical_or(cleaned_stack[..., 0], cleaned_stack[..., 1])\n",
    "\n",
    "# Loop over each z-plane\n",
    "for z_plane in range(image_stack.shape[0]):\n",
    "    # Create the figure and axes\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # Display the original image\n",
    "    ax.imshow(image_stack[z_plane, 0], cmap='gray')\n",
    "\n",
    "    # Display the segmented volume as outlines\n",
    "    for channel in range(image_stack.shape[1]):\n",
    "        ax =plt.figure()\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(image_stack[z_plane, channel], cmap='gray')\n",
    "        plt.title('Original Image')\n",
    "\n",
    "        # Display the segmented volume\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(cleaned_stack[z_plane], cmap='gray')\n",
    "        plt.title('Segmented Volume')\n",
    "        #ax.imshow(mark_boundaries(image_stack[z_plane, channel], cleaned_stack[z_plane, channel], color=colors_rgb[channel]), cmap=cmap)\n",
    "\n",
    "    # Set the axes labels and title\n",
    "        \n",
    "        #plt.title(f'Z-Plane {z_plane}, {channel}')\n",
    "\n",
    "        # Save the figure\n",
    "        plt.savefig(os.path.join(output_dir, f\"z_plane_{z_plane}_{channel}_segmentation.png\"))\n",
    "        plt.close(fig)  # Close the figure to release memory\n",
    "\n",
    "\n",
    "\n",
    "# Create the figure and axes for the stacked plot\n",
    "fig, axs = plt.subplots(cleaned_stack.shape[0], 2, sharex='all', sharey='all', figsize=(10, 10))\n",
    "\n",
    "# Loop over each z-plane\n",
    "for z_plane in range(cleaned_stack.shape[0]):\n",
    "    # Display the original image in the first column\n",
    "    axs[z_plane, 0].imshow(image_stack[z_plane, 0], cmap='gray')\n",
    "    axs[z_plane, 0].set_title(f'Z-Plane {z_plane}')\n",
    "\n",
    "    # Display the segmented volume in the second column\n",
    "    axs[z_plane, 1].imshow(cleaned_stack[z_plane])\n",
    "    axs[z_plane, 1].set_title('Segmented Volume')\n",
    "\n",
    "# Set the axes labels\n",
    "fig.text(0.5, 0.04, 'X', ha='center')\n",
    "fig.text(0.04, 0.5, 'Y', va='center', rotation='vertical')\n",
    "\n",
    "# Adjust the layout and save the figure\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, \"segmentation_stacked.png\"))\n",
    "plt.close(fig)  # Close the figure to release memory\n",
    "\n",
    "\n",
    "# Determine the bounding box of the segmented volume\n",
    "bbox = np.argwhere(merged_stack)\n",
    "(min_y, min_x), (max_y, max_x) = bbox.min(0), bbox.max(0)\n",
    "\n",
    "# Add padding\n",
    "padding = 50\n",
    "min_x, max_x = max(0, min_x - padding), min(max_x + padding, image_stack.shape[3])\n",
    "min_y, max_y = max(0, min_y - padding), min(max_y + padding, image_stack.shape[2])\n",
    "\n",
    "# Resize the image and segmented volume\n",
    "resized_image = resize(image_stack[:, :, min_y:max_y, min_x:max_x], (image_stack.shape[0], 2, 512, 512))\n",
    "resized_segmentation = resize(merged_stack[:, min_y:max_y, min_x:max_x], (image_stack.shape[0], 512, 512))\n",
    "\n",
    "io.imsave(os.path.join(output_dir, \"resized_image.tif\"), resized_image, plugin='tifffile')\n",
    "np.save(os.path.join(output_dir, \"resized_segmentation.npy\"), resized_segmentation)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df=pd.DataFrame.from_dict(metadata_dict, orient='index')\n",
    "df.to_csv(os.path.join(input_dir, 'metadata.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('channel_masks.h5', 'w') as hdf:\n",
    "    for key, value in channel_masks.items():\n",
    "        group = hdf.create_group(key)\n",
    "                \n",
    "        for inner_key, inner_value in value.items():\n",
    "            print(inner_value)\n",
    "            if isinstance(inner_value, np.ndarray):\n",
    "                group.create_dataset(inner_key, data=inner_value)\n",
    "            else:\n",
    "                # Store small metadata as attributes\n",
    "                group.attrs[inner_key] = inner_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('channel_masks.h5', 'r') as hdf:\n",
    "    print(hdf)\n",
    "    for group_name in hdf:\n",
    "        print(group_name)\n",
    "        group = hdf[group_name]\n",
    "        for dataset_name in group:\n",
    "            dataset = group[dataset_name]\n",
    "            data = dataset[...]  # Read the data\n",
    "            print(f\"Data in {dataset_name}: {data}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "channels = pd.DataFrame.from_dict(channel_masks, orient='index')\n",
    "channels.to_csv('channel_masks_2.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from naparimovie import Movie\n",
    "from napari_animation import Animation\n",
    "import vispy\n",
    "\n",
    "viewer = napari.Viewer()\n",
    "\n",
    "#red = vispy.color.Colormap([[0., 0.0, 0.0], [\n",
    "green = vispy.color.Colormap([[0.8, 1.0, 0.8], [0.0, 1.0, 0.0]])\n",
    "blue = vispy.color.Colormap([[0.0, 0.0, 0.0], [0.0, 0.0, 1.0]])\n",
    "\n",
    "for image, channel_info in channel_masks.items():\n",
    "    if image == 'B_3_M04_OC_L23_P+_061123_1.tif':\n",
    "        print(image)\n",
    "        # 'channel_info' is the nested dictionary for each image\n",
    "        for channel, masks in channel_info.items():\n",
    "            print(channel)\n",
    "            if channel == 0:\n",
    "                #label = Colormap(['#EE82EE'])\n",
    "                # This is the list of all masks, handle accordingly\n",
    "                # ... process 'mask_list' which contains all masks for this image ...\n",
    "                \n",
    "                stacked_masks = np.stack(masks, axis=0)\n",
    "                # Stack boundaries similarly\n",
    "                stacked_boundaries = np.stack([find_boundaries(mask) for mask in masks], axis=0)\n",
    "\n",
    "                # Add original mask\n",
    "                #viewer.add_image(stacked_masks, name=f'Channel {channel} Masks', contrast_limits=(0, 1))\n",
    "\n",
    "                # Add boundaries as another layer\n",
    "                labels=viewer.add_labels(stacked_boundaries, name=f'Channel {channel} Boundaries')\n",
    "                #labels.colormap = 'blue', blue\n",
    "\n",
    "            elif channel== 1:\n",
    "\n",
    "                stacked_masks = np.stack(masks, axis=0)\n",
    "                # Stack boundaries similarly\n",
    "                stacked_boundaries = np.stack([find_boundaries(mask) for mask in masks], axis=0)\n",
    "\n",
    "                # Add original mask\n",
    "                #viewer.add_image(stacked_masks, name=f'Channel {channel} Masks', contrast_limits=(0, 1))\n",
    "\n",
    "                # Add boundaries as another layer\n",
    "                labels = viewer.add_labels(stacked_boundaries, name=f'Channel {channel} Boundaries')\n",
    "                #labels=viewer.add_labels(stacked_boundaries, name=f'Channel {channel} Boundaries')\n",
    "                labels.blending='additive'\n",
    "                #labels.colormap = 'red', green\n",
    "\n",
    "                frames = []\n",
    "\n",
    "            #movie = Movie(viewer)\n",
    "            #movie.inter_steps = 30\n",
    "            #movie.make_movie(name = 'movie.mp4', resolution = 300, fps = 20)\n",
    "            #movie.make_gif('gifmovie.gif')\n",
    "            \n",
    "            napari.run()\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install git+https://github.com/guiwitz/naparimovie.git@master#egg=naparimovie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for channel, masks in channel_masks.items():\n",
    "    stacked_masks = np.stack(masks, axis=0)\n",
    "    # Stack boundaries similarly\n",
    "    stacked_boundaries = np.stack([find_boundaries(mask) for mask in masks], axis=0)\n",
    "\n",
    "    # Add original mask\n",
    "    viewer.add_image(stacked_masks, name=f'Channel {channel} Masks', contrast_limits=(0, 1))\n",
    "\n",
    "    # Add boundaries as another layer\n",
    "    viewer.add_labels(stacked_boundaries, name=f'Channel {channel} Boundaries')\n",
    "\n",
    "    napari.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.Viewer()\n",
    "\n",
    "for channel, masks in channel_masks.items():\n",
    "    print(channel)\n",
    "    stacked_masks = np.stack(masks, axis=0)\n",
    "    # Stack boundaries similarly\n",
    "    stacked_boundaries = np.stack([find_boundaries(mask) for mask in masks], axis=0)\n",
    "\n",
    "    # Add original mask\n",
    "    viewer.add_image(stacked_masks, name=f'Channel {channel} Masks', contrast_limits=(0, 1))\n",
    "\n",
    "    # Add boundaries as another layer\n",
    "    viewer.add_labels(stacked_boundaries, name=f'Channel {channel} Boundaries')\n",
    "\n",
    "    napari.run()\n",
    "\n",
    "for channel, masks in channel_masks.items():\n",
    "    for i, mask in enumerate(masks):\n",
    "        # Find boundaries\n",
    "        boundaries = find_boundaries(mask)\n",
    "\n",
    "        # Visualize in Matplotlib\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.imshow(mask, cmap='gray')  # Show the original mask\n",
    "        plt.imshow(boundaries, cmap='magma', alpha=0.5)  # Overlay boundaries\n",
    "        plt.title(f'Channel {channel} - Mask {i} with Boundaries')\n",
    "        plt.show()\n",
    "\n",
    "video_path = os.path.join(outputfolder, '3dvideo.mp4')\n",
    "\n",
    "# Record a video\n",
    "with napari.gui_qt():\n",
    "    # Set the desired duration and frames per second for the video\n",
    "    total_duration_sec = 5\n",
    "    fps = 30\n",
    "\n",
    "    total_frames = total_duration_sec * fps\n",
    "    for frame in range(total_frames):\n",
    "        # Here you can modify the viewer, e.g., rotate or zoom\n",
    "        # Example: Rotate the view\n",
    "        viewer.dims.ndisplay = 3\n",
    "        viewer.dims.point = [frame, frame, frame]  # Change this as needed\n",
    "        # Capture the frame\n",
    "        nbscreenshot(viewer, canvas_only=False).save(f'{frame}.png')\n",
    "\n",
    "    # Use imageio to compile the saved frames into a video\n",
    "    import imageio\n",
    "    with imageio.get_writer(video_path, fps=fps) as writer:\n",
    "        for frame in range(total_frames):\n",
    "            writer.append_data(imageio.imread(f'{frame}.png'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import skimage.io as io\n",
    "from skimage.filters import threshold_otsu\n",
    "from scipy.ndimage import label, binary_fill_holes\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from skimage.transform import resize\n",
    "from matplotlib.colors import ListedColormap\n",
    "from skimage import io, exposure, data\n",
    "from skimage.filters import gaussian\n",
    "from skimage.filters import threshold_local\n",
    "from skimage.filters import try_all_threshold\n",
    "from skimage.filters import threshold_yen, sobel, threshold_isodata, threshold_multiotsu\n",
    "import napari\n",
    "import pandas as pd\n",
    "from skimage.segmentation import find_boundaries\n",
    "\n",
    "\n",
    "\n",
    "input_dir = \"/Users/katherineridley/APPFIRE_image/TIFFs/\"\n",
    "output_dir = \"/Users/katherineridley/APPFIRE_image/TIFFs/thresholded/\"\n",
    "os.makedirs(output_dir, exist_ok=True)  # Create directory if it doesn't exist\n",
    "\n",
    "plaques = [image for image in os.listdir(input_dir) if 'P+' in image]\n",
    "viewer = napari.Viewer()\n",
    "\n",
    "# Initialize a dictionary to store masks for each channel\n",
    "fl_channels = [0, 1]\n",
    "channel_masks = {channel: [] for channel in fl_channels}\n",
    "\n",
    "\n",
    "\n",
    "#for image in plaques:\n",
    "\n",
    "image = 'F_3_M04_OC_L1_P+_231123_1.tif'\n",
    "# Construct the control image filename by replacing 'P+' with 'P-'\n",
    "control_image = image.replace('P+', 'P-')\n",
    "\n",
    "# Read the experimental image stack\n",
    "image_stack = io.imread(os.path.join(input_dir, image))\n",
    "\n",
    "# Read the corresponding negative control image stack\n",
    "control_stack = io.imread(os.path.join(input_dir, control_image))\n",
    "\n",
    "# Ensure the dimensions match between the image and control stacks\n",
    "assert image_stack.shape == control_stack.shape, \"Mismatch in image and control stack dimensions\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "outputfolder = os.path.join(output_dir, image)\n",
    "os.makedirs(outputfolder, exist_ok=True) \n",
    "# Define fluorescent channels\n",
    "\n",
    "\n",
    "# Initialize a dictionary to store thresholds\n",
    "\n",
    "for channel in fl_channels:\n",
    "    if channel == 0:\n",
    "        protein = 'Methoxy-0-4'\n",
    "\n",
    "    else:\n",
    "        protein = 'OC'\n",
    "\n",
    "    binary_masks = []\n",
    "    # Process each z-plane\n",
    "    for z_plane in range(image_stack.shape[0]):\n",
    "        # Calculate the central region\n",
    "        height, width = image_stack[z_plane, channel].shape\n",
    "        center_y, center_x = height // 2, width // 2\n",
    "        delta_y, delta_x = height // 4, width // 4  # 50% of the height and width\n",
    "        y_min, y_max = center_y - delta_y, center_y + delta_y\n",
    "        x_min, x_max = center_x - delta_x, center_x + delta_x\n",
    "\n",
    "        center_fraction = 0.4  # For example, use 40% of the height and width instead of 50%\n",
    "        delta_y, delta_x = int(height * center_fraction / 2), int(width * center_fraction / 2)\n",
    "        y_min, y_max = center_y - delta_y, center_y + delta_y\n",
    "        x_min, x_max = center_x - delta_x, center_x + delta_x\n",
    "\n",
    "        # Crop the smaller central region\n",
    "        central_region = image_stack[z_plane, channel][y_min:y_max, x_min:x_max]\n",
    "\n",
    "        central_control = control_stack[z_plane, channel][y_min:y_max, x_min:x_max]\n",
    "\n",
    "        backgroundthreshold = threshold_otsu(central_control)\n",
    "        originalthreshold = threshold_otsu(central_region)\n",
    "        #print('whole image:', np.mean(image_stack), 'central z plane:', np.mean(central_region), 'whole control:', np.mean(control_stack), 'control z plane:', np.mean(central_control))\n",
    "\n",
    "        background_corrected_image = (central_region.astype(np.float32) - (central_control.astype(np.float32)))\n",
    "        \n",
    "        # Set any negative values to zero\n",
    "        background_corrected_image[background_corrected_image < 0] = 0\n",
    "\n",
    "        hard_cutoff= 5\n",
    "        image_cutoff = image_stack > hard_cutoff\n",
    "        v_min, v_max = np.percentile(background_corrected_image, (0.05, 99.99))\n",
    "        # Apply threshold to the central region\n",
    "        image_minmax_scaled = exposure.rescale_intensity(background_corrected_image, in_range=(v_min, v_max), out_range=(0,50))\n",
    "        \n",
    "        #print('mean:', np.mean(image_minmax_scaled))\n",
    "        #print('max:',np.max(image_minmax_scaled))\n",
    "        #sigma=1\n",
    "        #blurred_image = gaussian(image_minmax_scaled, sigma=sigma, mode='nearest')\n",
    "        \n",
    "        #better_contrast = exposure.rescale_intensity(image_minmax_scaled[z_plane, channel], in_range=(v_min, v_max))\n",
    "        threshold_value = (threshold_otsu(image_minmax_scaled))\n",
    "\n",
    "        #threshold_value = threshold_local(central_region, block_size=3, offset=-0.1)\n",
    "\n",
    "        #apply thrshold from entire stack>>\n",
    "        '''image_minmax_scaled = exposure.rescale_intensity(image_stack)\n",
    "        sigma=0.1\n",
    "        #blurred_image = gaussian(image_stack, sigma=sigma, mode='nearest')\n",
    "        v_min, v_max = np.percentile(image_stack, (0.2, 99.8))\n",
    "\n",
    "        \n",
    "\n",
    "        better_contrast = exposure.rescale_intensity(image_minmax_scaled)\n",
    "        threshold_value = threshold_otsu(image_stack[:, channel])\n",
    "        intensity_cutoff = np.percentile(image_stack, 20) \n",
    "        if channel == 0:\n",
    "            offset = 0.3\n",
    "        else:\n",
    "            offset = 1\n",
    "        threshold_value = threshold_value * offset'''\n",
    "        \n",
    "        #binary_mask = central_region > threshold_value\n",
    "\n",
    "        #>>new code<<\n",
    "        #block_size = 35  # This is a parameter you may need to tune\n",
    "        #local_thresh = threshold_local(central_region, block_size, offset=50)\n",
    "        #binary_mask = central_region > local_thresh\n",
    "\n",
    "        binary_mask = central_region > threshold_value\n",
    "\n",
    "        #print(threshold_value)\n",
    "\n",
    "\n",
    "        # Process the binary mask\n",
    "        filled_mask = binary_fill_holes(binary_mask)\n",
    "        cleaned_mask, _ = label(filled_mask)\n",
    "        size = np.bincount(cleaned_mask.flatten())\n",
    "\n",
    "        # Check if there are non-zero elements in 'size' after the first element\n",
    "        if len(size) > 1:\n",
    "            largest_component = np.argmax(size[1:]) + 1\n",
    "            cleaned_mask = cleaned_mask == largest_component\n",
    "        else:\n",
    "            # If no connected components, use an empty mask\n",
    "            cleaned_mask = np.zeros_like(cleaned_mask)\n",
    "\n",
    "        # Create an empty mask for the whole image\n",
    "        full_cleaned_mask = np.zeros_like(image_stack[z_plane, channel])\n",
    "        # Place the processed central region back into the full mask\n",
    "        full_cleaned_mask[y_min:y_max, x_min:x_max] = cleaned_mask\n",
    "\n",
    "        #print(full_cleaned_mask)\n",
    "\n",
    "        # Instead of binary_masks.append, use:\n",
    "        channel_masks[channel].append(full_cleaned_mask)\n",
    "        \n",
    "\n",
    "\n",
    "        # After processing all images, add them to the viewer\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        #brightness_increase = 1000  # Adjust this value as needed\n",
    "\n",
    "        # Increase brightness\n",
    "        #brightened_image = image_stack + brightness_increase\n",
    "\n",
    "        '''image_minmax_scaled = exposure.rescale_intensity(background_corrected_image)\n",
    "        better_contrast = exposure.rescale_intensity(image_minmax_scaled)\n",
    "        v_min, v_max = np.percentile(image_stack, (0.2, 99.8))\n",
    "\n",
    "        \n",
    "\n",
    "        better_contrast = exposure.rescale_intensity(image_stack, in_range=(v_min, v_max))\n",
    "        #fig, ax = try_all_threshold(z_plane, figsize=(10, 8), verbose=False)\n",
    "        #plt.show()\n",
    "\n",
    "        # Visualize the results\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.suptitle(f'Protein {protein}, Z-Plane: {z_plane}')\n",
    "\n",
    "        # Display the original image for the current z-plane\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(better_contrast[z_plane, channel], cmap='gray')\n",
    "        plt.title('Original Image')\n",
    "\n",
    "        # Display the segmented volume for the current z-plane\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(full_cleaned_mask, cmap='gray')\n",
    "        plt.title('Segmented Volume')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(outputfolder, f\"{image}_{z_plane}_c{channel}_thresh_otsu.png\"))\n",
    "        plt.show()'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for channel, masks in channel_masks.items():\n",
    "    stacked_masks = np.stack(masks, axis=0)\n",
    "    # Stack boundaries similarly\n",
    "    stacked_boundaries = np.stack([find_boundaries(mask) for mask in masks], axis=0)\n",
    "\n",
    "    # Add original mask\n",
    "    viewer.add_image(stacked_masks, name=f'Channel {channel} Masks', contrast_limits=(0, 1))\n",
    "\n",
    "    # Add boundaries as another layer\n",
    "    viewer.add_labels(stacked_boundaries, name=f'Channel {channel} Boundaries')\n",
    "\n",
    "napari.run()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile as tiff\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "# Read the OME-TIFF file\n",
    "img_stack = tiff.imread('/Users/katherineridley/APPFIRE_image/OMETIFFs/F_2_M04_OC_L23_P+_231123_1_c0.ome.tiff', is_ome=False)\n",
    "\n",
    "# Check if the image stack has been loaded\n",
    "assert img_stack is not None, \"file could not be read, check with os.path.exists()\"\n",
    "\n",
    "# Process each slice in the Z-stack\n",
    "for z in range(img_stack.shape[0]):  # Assuming Z is the first dimension\n",
    "    img = img_stack[z, :, :]\n",
    "\n",
    "    # Convert to grayscale if necessary\n",
    "    if len(img.shape) > 2:\n",
    "        gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray = img\n",
    "\n",
    "    # Apply your existing processing steps to each slice\n",
    "    # For example, thresholding:\n",
    "    ret, thresh = cv.threshold(gray, 0, 255, cv.THRESH_BINARY_INV + cv.THRESH_OTSU)\n",
    "    # noise removal\n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "    opening = cv.morphologyEx(thresh,cv.MORPH_OPEN,kernel, iterations = 2)\n",
    "    # sure background area\n",
    "    sure_bg = cv.dilate(opening,kernel,iterations=3)\n",
    "    # Finding sure foreground area\n",
    "    dist_transform = cv.distanceTransform(opening,cv.DIST_L2,5)\n",
    "    ret, sure_fg = cv.threshold(dist_transform,0.7*dist_transform.max(),255,0)\n",
    "    sure_fg = np.uint8(sure_fg)\n",
    "\n",
    "    unknown = cv.subtract(sure_bg,sure_fg)\n",
    "\n",
    "    # Marker labelling\n",
    "    ret, markers = cv.connectedComponents(sure_fg)\n",
    "    # Add one to all labels so that sure background is not 0, but 1\n",
    "    markers = markers+1\n",
    "    # Now, mark the region of unknown with zero\n",
    "    markers[unknown==255] = 0\n",
    "\n",
    "    #markers = cv.watershed(img,markers)\n",
    "    #img[markers == -1] = [255,0,0]\n",
    "    # ... continue with your processing steps\n",
    "\n",
    "    # Display the processed slice\n",
    "    cv.imshow(f'Slice {z}', gray)\n",
    "    cv.waitKey(0)\n",
    "\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### java dependencies need sorting before being able to deploy javabridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## skeleton notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import javabridge\n",
    "import bioformats\n",
    "import numpy as np\n",
    "from tifffile import imsave\n",
    "\n",
    "def lif_to_tiff(input_path, output_dir, ome_tiff=False):\n",
    "    # Start the Java Virtual Machine\n",
    "    javabridge.start_vm(class_path=bioformats.JARS)\n",
    "\n",
    "    # Read the .lif file with bioformats\n",
    "    r = bioformats.ImageReader(input_path)\n",
    "    \n",
    "    # Determine number of series (individual images) in the .lif file\n",
    "    n_series = r.rdr.getSeriesCount()\n",
    "\n",
    "    for series in range(n_series):\n",
    "        r.rdr.setSeries(series)\n",
    "        \n",
    "        # Get image dimensions\n",
    "        x, y, z, c, t = (r.rdr.getSizeX(), r.rdr.getSizeY(), r.rdr.getSizeZ(), \n",
    "                         r.rdr.getSizeC(), r.rdr.getSizeT())\n",
    "\n",
    "        # Initialize an empty array for image data\n",
    "        img_data = np.empty((t, z, y, x, c), dtype=np.uint16)\n",
    "\n",
    "        # Fill the array with image data\n",
    "        for ti in range(t):\n",
    "            for zi in range(z):\n",
    "                for ci in range(c):\n",
    "                    img_data[ti, zi, :, :, ci] = r.read(z=zi, t=ti, c=ci, rescale=False)\n",
    "\n",
    "        # Save as TIFF or OME-TIFF\n",
    "        filename = f\"image_series_{series}\"\n",
    "        filepath = os.path.join(output_dir, filename + ('.ome.tiff' if ome_tiff else '.tiff'))\n",
    "        imsave(filepath, img_data)\n",
    "\n",
    "    # Close the Java Virtual Machine\n",
    "    javabridge.kill_vm()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_lif = \"path_to_your_file.lif\"\n",
    "    output_directory = \"path_for_output_files\"\n",
    "    lif_to_tiff(input_lif, output_directory, ome_tiff=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##concepts: NOT EXECUTABLE\n",
    "\n",
    "import numpy as np\n",
    "import javabridge\n",
    "import bioformats\n",
    "\n",
    "from skimage import morphology, measure, filters\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize Java Virtual Machine\n",
    "javabridge.start_vm(class_path=bioformats.JARS)\n",
    "\n",
    "def load_ome_tiff(file_path):\n",
    "    # Read OME-TIFF using bioformats\n",
    "    img, meta = bioformats.read_image(file_path, rescale=False, wants_max_intensity=True, return_metadata=True)\n",
    "    return img, meta\n",
    "\n",
    "def preprocess(data):\n",
    "    # Preprocessing steps, e.g., normalization\n",
    "    return (data - data.min()) / (data.max() - data.min())\n",
    "\n",
    "def segment(data):\n",
    "    # Segmentation using a simple threshold (this can be replaced with more complex methods)\n",
    "    threshold = filters.threshold_otsu(data)\n",
    "    return data > threshold\n",
    "\n",
    "def morphological_analysis(data):\n",
    "    convex_hull = morphology.convex_hull_image(data)\n",
    "    complexity = measure.perimeter(data) / np.sqrt(4 * np.pi * measure.area(data))\n",
    "    return convex_hull, complexity\n",
    "\n",
    "def extract_features(data):\n",
    "    # Feature extraction for ML\n",
    "    features = {\n",
    "        'mean_intensity': np.mean(data),\n",
    "        'standard_deviation': np.std(data)\n",
    "    }\n",
    "    return features\n",
    "\n",
    "def ml_model(features, labels):\n",
    "    # Train a simple random forest classifier for this example\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2)\n",
    "    clf = RandomForestClassifier()\n",
    "    clf.fit(X_train, y_train)\n",
    "    accuracy = clf.score(X_test, y_test)\n",
    "    return accuracy\n",
    "\n",
    "# Main execution\n",
    "file_path = \"path_to_your_ome.tiff\"\n",
    "image, metadata = load_ome_tiff(file_path)\n",
    "processed_image = preprocess(image)\n",
    "binary_image = segment(processed_image)\n",
    "convex, complexity = morphological_analysis(binary_image)\n",
    "\n",
    "# Extract features from each image for ML (you'd loop over many images here)\n",
    "features = []\n",
    "labels = []  # You would also need a label for each image\n",
    "features.append(extract_features(binary_image))\n",
    "\n",
    "# Train ML model\n",
    "accuracy = ml_model(features, labels)\n",
    "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Shutdown JVM\n",
    "javabridge.kill_vm()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## READ TIFF STACK\n",
    "\n",
    "from tifffile import imread\n",
    "stack = imread('/Users/katherineridley/APPFIRE_image/OMETIFFs/A_4_M04_OC_P+_CA1_011123_1_c0.ome.tiff', is_ome=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from skimage.filters import gaussian\n",
    "smoothed = gaussian(stack, sigma=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.filters import threshold_otsu\n",
    "thresh = threshold_otsu(smoothed)\n",
    "binary = smoothed > thresh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALTERNATIVES TO THRESHOLDING\n",
    "While thresholding is a basic technique, many advanced alternatives can yield better segmentation results, especially in challenging datasets with variability in intensity, noise, and other artifacts. Some of the more advanced alternatives to threshold-based segmentation include:\n",
    "\n",
    "1. **Active Contours (Snake Algorithms)**:\n",
    "    - Active contours aim to find an optimal curve (in 2D) or surface (in 3D) separating the object from the background.\n",
    "    - The initial contour is iteratively evolved by considering image-based forces (like gradients) and internal constraints (like smoothness or elasticity).\n",
    "\n",
    "2. **Watershed Segmentation**:\n",
    "    - This method treats image intensity as a topographic landscape with hills and valleys.\n",
    "    - \"Floodwaters\" are poured onto this landscape from predefined markers, and \"basins\" are filled up, resulting in segmented regions.\n",
    "\n",
    "3. **Random Forests and Machine Learning**:\n",
    "    - This approach involves training a classifier (like Random Forest) using handpicked features from labeled examples of the regions of interest and background.\n",
    "    - Once the classifier is trained, it can be used to predict the class (object or background) of every pixel or voxel in the image.\n",
    "\n",
    "4. **Deep Learning and Convolutional Neural Networks (CNNs)**:\n",
    "    - Deep learning, especially CNNs, has achieved state-of-the-art performance in many segmentation tasks.\n",
    "    - U-Net is a popular CNN architecture designed for biomedical image segmentation. It requires labeled training data.\n",
    "    - Transfer learning, where a pre-trained model is fine-tuned on a smaller dataset, can be useful if you don't have a large annotated dataset.\n",
    "\n",
    "5. **Level Set Methods**:\n",
    "    - Level set methods represent a curve (in 2D) or a surface (in 3D) as the zero level of a higher-dimensional function.\n",
    "    - This implicit representation is evolved over time according to predefined criteria, allowing for topological changes and providing a flexible framework for segmentation.\n",
    "\n",
    "6. **Graph-based Segmentation**:\n",
    "    - In this method, an image is represented as a graph, where pixels/voxels are nodes and edges are defined based on pixel/voxel relationships.\n",
    "    - Graph cuts or minimum cut methods can be used to find the optimal segmentation.\n",
    "\n",
    "7. **Region Growing**:\n",
    "    - Starting from a seed point, pixels or voxels are iteratively added to the region based on predefined criteria, such as intensity similarity.\n",
    "\n",
    "8. **Atlas-guided and Model-based Methods**:\n",
    "    - For structured images (like MRIs of the brain), predefined models or atlases can guide the segmentation.\n",
    "    - These methods aim to match or register the model to the observed data, benefiting from prior knowledge about the structure of interest.\n",
    "\n",
    "When choosing an advanced method, it's essential to consider the nature of your data, the availability of labeled training data (for supervised methods), computational resources, and the specific challenges your images present (e.g., low contrast, overlapping objects). Often, combining multiple methods (ensemble methods or hybrid approaches) or post-processing steps can improve results further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from skimage.morphology import opening, closing, disk\n",
    "refined = opening(binary, disk(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.morphology import skeletonize_3d\n",
    "skeleton = skeletonize_3d(refined)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.measure import label, regionprops\n",
    "\n",
    "labeled = label(binary)\n",
    "properties = regionprops(binary)\n",
    "\n",
    "for prop in properties:\n",
    "    volume = prop.area\n",
    "    eccentricity = prop.eccentricity\n",
    "    \n",
    "\n",
    "    \n",
    "    # ... and other measurements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari\n",
    "\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(your_confocal_data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
