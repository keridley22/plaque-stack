{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install jni"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### java dependencies need sorting before being able to deploy javabridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install git+https://github.com/LeeKamentsky/python-javabridge.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## skeleton notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##concepts: NOT EXECUTABLE\n",
    "\n",
    "import numpy as np\n",
    "import bioformats\n",
    "import javabridge\n",
    "from skimage import morphology, measure, filters\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize Java Virtual Machine\n",
    "javabridge.start_vm(class_path=bioformats.JARS)\n",
    "\n",
    "def load_ome_tiff(file_path):\n",
    "    # Read OME-TIFF using bioformats\n",
    "    img, meta = bioformats.read_image(file_path, rescale=False, wants_max_intensity=True, return_metadata=True)\n",
    "    return img, meta\n",
    "\n",
    "def preprocess(data):\n",
    "    # Preprocessing steps, e.g., normalization\n",
    "    return (data - data.min()) / (data.max() - data.min())\n",
    "\n",
    "def segment(data):\n",
    "    # Segmentation using a simple threshold (this can be replaced with more complex methods)\n",
    "    threshold = filters.threshold_otsu(data)\n",
    "    return data > threshold\n",
    "\n",
    "def morphological_analysis(data):\n",
    "    convex_hull = morphology.convex_hull_image(data)\n",
    "    complexity = measure.perimeter(data) / np.sqrt(4 * np.pi * measure.area(data))\n",
    "    return convex_hull, complexity\n",
    "\n",
    "def extract_features(data):\n",
    "    # Feature extraction for ML\n",
    "    features = {\n",
    "        'mean_intensity': np.mean(data),\n",
    "        'standard_deviation': np.std(data)\n",
    "    }\n",
    "    return features\n",
    "\n",
    "def ml_model(features, labels):\n",
    "    # Train a simple random forest classifier for this example\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2)\n",
    "    clf = RandomForestClassifier()\n",
    "    clf.fit(X_train, y_train)\n",
    "    accuracy = clf.score(X_test, y_test)\n",
    "    return accuracy\n",
    "\n",
    "# Main execution\n",
    "file_path = \"path_to_your_ome.tiff\"\n",
    "image, metadata = load_ome_tiff(file_path)\n",
    "processed_image = preprocess(image)\n",
    "binary_image = segment(processed_image)\n",
    "convex, complexity = morphological_analysis(binary_image)\n",
    "\n",
    "# Extract features from each image for ML (you'd loop over many images here)\n",
    "features = []\n",
    "labels = []  # You would also need a label for each image\n",
    "features.append(extract_features(binary_image))\n",
    "\n",
    "# Train ML model\n",
    "accuracy = ml_model(features, labels)\n",
    "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Shutdown JVM\n",
    "javabridge.kill_vm()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LIF TO TIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import javabridge\n",
    "import bioformats\n",
    "import numpy as np\n",
    "from tifffile import imsave\n",
    "\n",
    "def lif_to_tiff(input_path, output_dir, ome_tiff=False):\n",
    "    # Start the Java Virtual Machine\n",
    "    javabridge.start_vm(class_path=bioformats.JARS)\n",
    "\n",
    "    # Read the .lif file with bioformats\n",
    "    r = bioformats.ImageReader(input_path)\n",
    "    \n",
    "    # Determine number of series (individual images) in the .lif file\n",
    "    n_series = r.rdr.getSeriesCount()\n",
    "\n",
    "    for series in range(n_series):\n",
    "        r.rdr.setSeries(series)\n",
    "        \n",
    "        # Get image dimensions\n",
    "        x, y, z, c, t = (r.rdr.getSizeX(), r.rdr.getSizeY(), r.rdr.getSizeZ(), \n",
    "                         r.rdr.getSizeC(), r.rdr.getSizeT())\n",
    "\n",
    "        # Initialize an empty array for image data\n",
    "        img_data = np.empty((t, z, y, x, c), dtype=np.uint16)\n",
    "\n",
    "        # Fill the array with image data\n",
    "        for ti in range(t):\n",
    "            for zi in range(z):\n",
    "                for ci in range(c):\n",
    "                    img_data[ti, zi, :, :, ci] = r.read(z=zi, t=ti, c=ci, rescale=False)\n",
    "\n",
    "        # Save as TIFF or OME-TIFF\n",
    "        filename = f\"image_series_{series}\"\n",
    "        filepath = os.path.join(output_dir, filename + ('.ome.tiff' if ome_tiff else '.tiff'))\n",
    "        imsave(filepath, img_data)\n",
    "\n",
    "    # Close the Java Virtual Machine\n",
    "    javabridge.kill_vm()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_lif = \"path_to_your_file.lif\"\n",
    "    output_directory = \"path_for_output_files\"\n",
    "    lif_to_tiff(input_lif, output_directory, ome_tiff=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## READ TIFF STACK\n",
    "\n",
    "from tifffile import imread\n",
    "stack = imread('path_to_your_stack.tif')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from skimage.filters import gaussian\n",
    "smoothed = gaussian(stack, sigma=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.filters import threshold_otsu\n",
    "thresh = threshold_otsu(smoothed)\n",
    "binary = smoothed > thresh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALTERNATIVES TO THRESHOLDING\n",
    "While thresholding is a basic technique, many advanced alternatives can yield better segmentation results, especially in challenging datasets with variability in intensity, noise, and other artifacts. Some of the more advanced alternatives to threshold-based segmentation include:\n",
    "\n",
    "1. **Active Contours (Snake Algorithms)**:\n",
    "    - Active contours aim to find an optimal curve (in 2D) or surface (in 3D) separating the object from the background.\n",
    "    - The initial contour is iteratively evolved by considering image-based forces (like gradients) and internal constraints (like smoothness or elasticity).\n",
    "\n",
    "2. **Watershed Segmentation**:\n",
    "    - This method treats image intensity as a topographic landscape with hills and valleys.\n",
    "    - \"Floodwaters\" are poured onto this landscape from predefined markers, and \"basins\" are filled up, resulting in segmented regions.\n",
    "\n",
    "3. **Random Forests and Machine Learning**:\n",
    "    - This approach involves training a classifier (like Random Forest) using handpicked features from labeled examples of the regions of interest and background.\n",
    "    - Once the classifier is trained, it can be used to predict the class (object or background) of every pixel or voxel in the image.\n",
    "\n",
    "4. **Deep Learning and Convolutional Neural Networks (CNNs)**:\n",
    "    - Deep learning, especially CNNs, has achieved state-of-the-art performance in many segmentation tasks.\n",
    "    - U-Net is a popular CNN architecture designed for biomedical image segmentation. It requires labeled training data.\n",
    "    - Transfer learning, where a pre-trained model is fine-tuned on a smaller dataset, can be useful if you don't have a large annotated dataset.\n",
    "\n",
    "5. **Level Set Methods**:\n",
    "    - Level set methods represent a curve (in 2D) or a surface (in 3D) as the zero level of a higher-dimensional function.\n",
    "    - This implicit representation is evolved over time according to predefined criteria, allowing for topological changes and providing a flexible framework for segmentation.\n",
    "\n",
    "6. **Graph-based Segmentation**:\n",
    "    - In this method, an image is represented as a graph, where pixels/voxels are nodes and edges are defined based on pixel/voxel relationships.\n",
    "    - Graph cuts or minimum cut methods can be used to find the optimal segmentation.\n",
    "\n",
    "7. **Region Growing**:\n",
    "    - Starting from a seed point, pixels or voxels are iteratively added to the region based on predefined criteria, such as intensity similarity.\n",
    "\n",
    "8. **Atlas-guided and Model-based Methods**:\n",
    "    - For structured images (like MRIs of the brain), predefined models or atlases can guide the segmentation.\n",
    "    - These methods aim to match or register the model to the observed data, benefiting from prior knowledge about the structure of interest.\n",
    "\n",
    "When choosing an advanced method, it's essential to consider the nature of your data, the availability of labeled training data (for supervised methods), computational resources, and the specific challenges your images present (e.g., low contrast, overlapping objects). Often, combining multiple methods (ensemble methods or hybrid approaches) or post-processing steps can improve results further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from skimage.morphology import opening, closing, disk\n",
    "refined = opening(binary, disk(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.morphology import skeletonize_3d\n",
    "skeleton = skeletonize_3d(refined)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.measure import label, regionprops\n",
    "\n",
    "labeled = label(refined)\n",
    "properties = regionprops(labeled)\n",
    "\n",
    "for prop in properties:\n",
    "    volume = prop.area\n",
    "    eccentricity = prop.eccentricity\n",
    "\n",
    "    \n",
    "    # ... and other measurements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari\n",
    "\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(your_confocal_data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
